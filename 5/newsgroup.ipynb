{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# トピックモデリング\n",
    "\n",
    "自然言語で書かれた文章に対するデータマイニングをする必要があるとしましょう。\n",
    "\n",
    "文章中に現れる単語は同じ綴りであっても異なる意味を持っている場合があります。\n",
    "同じ綴りであっても名詞と動詞などのように文法的に違う場合は、構文規則などに従った解析などで区別できるかもしれませんが、\n",
    "品詞が同じでも意味が違う場合は、周りに存在する単語を勘案してどの意味で使われているのかを判断する必要があります。\n",
    "\n",
    "逆に言うと、真面目に構文解析などを行わなくても、共起する単語のセットを文章の背後に潜んでいる「潜在トピック」と考えることで、単語や文章について意味とかを扱える、ということになります。\n",
    "\n",
    "* 個々の文書 = 複数のトピックを混合したもの\n",
    "* 個々のトピック = 複数の単語が、個々のトピック毎に決まった割合で出現\n",
    "\n",
    "と、考えるということになります。\n",
    "\n",
    "文章の背後に潜んでいる潜在トピックは、数学的には、データに直接現れない潜在変数として扱うことになるので、それを用いて自分の解きたい問題を完全にモデル化するとなると、数学的にも、またそれを数値的に解くのも大変です。（それを真面目に扱っている佐藤先生の「トピックモデルによる統計的潜在意味解析」（オーム社）という教科書があります。）\n",
    "\n",
    "ですが、既存の潜在意味解析のライブラリを使うと、出来ることは限定的ではありますが、文章をトピックで表現する（＝次元削減）ことで、普通の機械学習のアルゴリズム（回帰や識別、クラスタリングなど）に使用できるようになります --- ということを前回お話ししました。いわゆる「次元の呪い」を避けるために次元削減することは重要です。\n",
    "\n",
    "また、文書 $\\rightarrow$ 顧客、単語 $\\rightarrow$ 購入アイテム、と読み替えを行えば、潜在トピック $\\rightarrow$ 潜在的な購買傾向、と考えることもできます。すると、潜在意味解析は商品リコメンデーションなどにそのまま応用できると考えられます。\n",
    "\n",
    "そこで今回は、gensim と呼ばれるライブラリの使い方をメインに扱います。\n",
    "\n",
    "# 20 newsgroups\n",
    "\n",
    "実際に我々が仕事で解析したい文章はおそらく日本語の文書であろうかと思われます。日本語の文書を解析する際には、形態素解析を使って文書の前処理をすることが多いと思いますので、授業の後半で python で形態素解析ライブラリを呼ぶ話をし、gensim の使い方自体は形態素解析が不要な英文で学ぶことにします。\n",
    "\n",
    "下記で gensim のライブラリのロードに失敗する場合は、一度 ipython notebook を閉じて\n",
    "````\n",
    "$ pip install gensim\n",
    "````\n",
    "のようにライブラリを導入してから、ipython notebook を再起動してください。\n",
    "\n",
    "また、`nltk` がファイルダウンロードが必要だとエラーを出してきた場合は、コマンドラインシェルから\n",
    "\n",
    "````\n",
    "$ ipython\n",
    "\n",
    "In [1]: import nltk\n",
    "\n",
    "In [2]: nltk.download()\n",
    "````\n",
    "\n",
    "のように入力すると、GUI のウィンドウが開くので、`all` をダウンロードしてください。（完了したら GUI のウィンドウを閉じて良い。また、多分不要なはず。）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from gensim import corpora, models, similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解析対象としていつもの 20 newsgroup データセットを使用します。下記を実行すると、ダウンロードに時間がかかる旨の WARNING が出ます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "texts0 = fetch_20newsgroups().data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "含まれる文書の数と、含まれているデータの形式は下記のようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(texts0[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u' I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = ['\\n'.join(text.split('\\n')[6:]) for text in texts0]\n",
    "texts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "newsgroup 記事としての各種ヘッダなどが含まれており、実務で解析する場合はそれらを除去するなど色々工夫すべき箇所があるかと思いますが、今回は非常に簡単にヘッダと思われる最初の６行をスキップして単語のリストに分解し、適当な前処理をしようと思います。\n",
    "\n",
    "`split()` は文字列をwhitespace文字で分割し、`lower()` は小文字化します。`re` ライブラリを使ってアルファベット以外の文字を消去します。\n",
    "短すぎる単語(a とか is とか)や、長すぎる単語(ドメイン名とか)も捨てます。\n",
    "英単語の語幹を取り出すアルゴリズムは nltk ライブラリには色々な stemming アルゴリズムが実装されていますが、簡単に正規表現で指定する `RegexpStemmer` を使用しました。また、stopword リストを作るのも今回は省略し、gensim の dictionary の機能に任せることにします。\n",
    "\n",
    "`wordss` は文字列のリストのリストになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#wordss = [[word for (word,tag) in pos_tag(word_tokenize(text)) \\\n",
    "#           if ((tag == 'NN') or (tag == 'NNP')) ] for text in texts]\n",
    "from nltk.stem import RegexpStemmer\n",
    "import re\n",
    "regex = re.compile('[^a-zA-Z]')\n",
    "st = RegexpStemmer('ing$|s$|e$|able$', min=4)\n",
    "wordss = [[st.stem(regex.sub('', word.lower())) for word in text.split() if 4 < len(word) < 10] for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回はテキストの総量が少ないため、文書全体をリストとして保持しています。gensim は文書にランダムアクセスを必要としないため、ドキュメントの[Corpus Streaming – One Document at a Time](https://radimrehurek.com/gensim/tut1.html#corpus-streaming-one-document-at-a-time) の記述を参考にすれば、必要に応じてテキストファイルから一行づつ文章を取得するイテレータとして実装することも可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'wonder',\n",
       " u'anyon',\n",
       " u'ther',\n",
       " u'could',\n",
       " u'enlighten',\n",
       " u'other',\n",
       " u'door',\n",
       " u'sport',\n",
       " u'looked',\n",
       " u'early',\n",
       " u'called',\n",
       " u'bricklin',\n",
       " u'door',\n",
       " u'really',\n",
       " u'small',\n",
       " u'addition',\n",
       " u'front',\n",
       " u'bumper',\n",
       " u'separat',\n",
       " u'body',\n",
       " u'know',\n",
       " u'anyon',\n",
       " u'tellm',\n",
       " u'model',\n",
       " u'nam',\n",
       " u'engin',\n",
       " u'spec',\n",
       " u'year',\n",
       " u'wher',\n",
       " u'mad',\n",
       " u'history',\n",
       " u'whatever',\n",
       " u'funky',\n",
       " u'look',\n",
       " u'pleas',\n",
       " u'email',\n",
       " u'thank',\n",
       " u'brought',\n",
       " u'lerxst']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordss[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記の単語のリストのリストから、「単語 $\\leftrightarrow$ 単語ID」の変換を行う辞書を作成します。今回は `wordss` を与えて一気に作成していますが、ふ大きなファイルから一文章づつ辞書に追加していく `add_documents` メソッドなどもあります。\n",
    "\n",
    "できた辞書から、出現頻度が少なすぎたり多すぎたりする単語を削除します。dictionary はファイルに save/load できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Dictionary(2459 unique tokens: [u'limited', u'selann', u'dynamic', u'catch', u'sleep']...)\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(wordss)\n",
    "dictionary.filter_extremes(no_below=50, no_above=0.1)\n",
    "dictionary.compactify()\n",
    "str(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag-of-Words 表現は dictionary を使ってこんな感じで得られます。この状態のデータを `corpora.MmCorpus.serialize` を使えば中間データとしてファイルに保存出来たりしますが、出力ファイルはサイズが割と大きめです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spec 1\n",
      "door 2\n",
      "history 1\n",
      "engin 1\n",
      "wonder 1\n",
      "sport 1\n",
      "model 1\n",
      "early 1\n",
      "separat 1\n",
      "small 1\n",
      "called 1\n",
      "nam 1\n",
      "body 1\n",
      "front 1\n",
      "mad 1\n",
      "brought 1\n",
      "looked 1\n",
      "addition 1\n",
      "know 1\n",
      "whatever 1\n"
     ]
    }
   ],
   "source": [
    "bows = [dictionary.doc2bow(words) for words in wordss]\n",
    "for i,c in bows[0]:\n",
    "    print dictionary.get(i), c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag-of-words の単語出現回数は、通常は Tf-Idf (Term Frequency(単語の出現頻度) $\\times$ Inverse Document Frequency (文書頻度の逆数)) に変換して用いることが多いかと思います。\n",
    "\n",
    "Bag-of-words から `tfidf_model` を作成し、bows を変換します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfModel(num_docs=11314, num_nnz=436786)\n",
      "spec 0.247740938814\n",
      "door 0.48991700211\n",
      "history 0.182941539255\n",
      "engin 0.220363090001\n",
      "wonder 0.16700783001\n",
      "sport 0.229373572547\n",
      "model 0.179354757006\n",
      "early 0.185873153278\n",
      "separat 0.224216878156\n",
      "small 0.16005216173\n",
      "called 0.144533517182\n",
      "nam 0.202307890205\n",
      "body 0.247740938814\n",
      "front 0.191757677553\n",
      "mad 0.233229293596\n",
      "brought 0.209988383367\n",
      "looked 0.200696329894\n",
      "addition 0.212154386206\n",
      "know 0.127904071636\n",
      "whatever 0.182656978796\n"
     ]
    }
   ],
   "source": [
    "tfidf_model = models.TfidfModel(bows, normalize=True)\n",
    "print str(tfidf_model)\n",
    "tfidfs = tfidf_model[bows]\n",
    "for i,tfidf in tfidf_model[bows[0]]:\n",
    "    print dictionary.get(i), tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA のトピックモデリングに先立って LSI (Latent Semantic Indexing) による解析を行ってみましょう。これは商品推薦アルゴリズムでは行列分解といわれるものに相当します。\n",
    "\n",
    "LSI を行うことで、文章が 500 次元のベクトルで表現されていることが判ります。\n",
    "\n",
    "固有値の値をプロットしてみます。トピックの数としては 100 も取れば十分そうに見えます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LsiModel(num_terms=2459, num_topics=500, decay=1.0, chunksize=20000)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEACAYAAACj0I2EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cba6cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lsi_model = models.LsiModel(tfidfs, id2word=dictionary, num_topics=500)\n",
    "print str(lsi_model)\n",
    "l = len(lsi_model.projection.s)\n",
    "plt.plot(np.linspace(0,100,100), lsi_model.projection.s[:100])\n",
    "plt.show()\n",
    "# print lsi_model[tfidf_model[bows[0]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、トピックモデリングのモデルとしてとして LDA (Latent Dirichlet Allocation) を使ってモデル化してみます。今回はトピックの数を上の議論により100に設定してみました。\n",
    "文章が、100次元のベクトルとして表現されていることが判ります。\n",
    "\n",
    "使用可能なアルゴリズムは、[gensim のドキュメント記述](https://radimrehurek.com/gensim/tut2.html#available-transformations)を読むと、LSI, random projection など幾つか選択肢があることが判ります。\n",
    "\n",
    "計算した `lda_model` も save/load メソッドでファイルに記録したり読みだしたりできます。\n",
    "\n",
    "`print_topics` メソッドの出力を眺めると、何をトピックと認識してるのかがわかります。\n",
    "\n",
    "注意：LDA はランダムな初期値から収束するまで計算させるので、結果は乱数で変わります。同じ結果になりません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LdaModel(num_terms=2459, num_topics=20, decay=0.5, chunksize=2000, alpha=[ 0.05  0.05  0.05  0.05  0.05  0.05  0.05  0.05  0.05  0.05  0.05  0.05\n",
      "  0.05  0.05  0.05  0.05  0.05  0.05  0.05  0.05])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[u'0.005*israel + 0.004*jesu + 0.004*israeli + 0.004*spac + 0.004*earth + 0.003*jewish + 0.003*greek + 0.003*orbit + 0.003*stat + 0.003*world',\n",
       " u'0.012*armenian + 0.009*russian + 0.009*ticket + 0.008*steal + 0.007*david + 0.006*citizen + 0.006*japanes + 0.006*bodie + 0.006*armenia + 0.006*turkish',\n",
       " u'0.024*monitor + 0.022*video + 0.017*card + 0.014*pric + 0.012*driver + 0.011*simm + 0.010*board + 0.010*offer + 0.010*speed + 0.009*centri',\n",
       " u'0.007*engin + 0.006*driv + 0.006*chip + 0.005*power + 0.005*motorola + 0.005*intel + 0.005*dealer + 0.005*appl + 0.004*model + 0.004*driver',\n",
       " u'0.010*doug + 0.009*phil + 0.009*penalty + 0.007*repost + 0.007*commit + 0.007*jackson + 0.006*blood + 0.006*grad + 0.006*macintosh + 0.006*beach',\n",
       " u'0.006*weapon + 0.004*koresh + 0.004*firearm + 0.003*polic + 0.003*criminal + 0.003*crim + 0.003*them + 0.003*compound + 0.003*member + 0.003*children',\n",
       " u'0.012*rid + 0.008*rider + 0.006*fax + 0.006*uniform + 0.006*tape + 0.005*editor + 0.005*edition + 0.005*chri + 0.005*w + 0.005*tommy',\n",
       " u'0.016*window + 0.013*file + 0.010*program + 0.009*sourc + 0.008*graphic + 0.008*imag + 0.007*version + 0.006*avail + 0.006*advanc + 0.006*widget',\n",
       " u'0.024*driv + 0.013*drive + 0.008*card + 0.008*thanx + 0.008*packag + 0.008*disk + 0.007*softwar + 0.006*advanc + 0.006*program + 0.006*replie',\n",
       " u'0.012*packag + 0.009*amiga + 0.008*chines + 0.008*brand + 0.007*specie + 0.007*virtual + 0.007*objectiv + 0.007*lebanes + 0.007*backup + 0.007*keith',\n",
       " u'0.023*window + 0.018*server + 0.013*client + 0.009*modem + 0.009*runn + 0.008*error + 0.008*display + 0.008*program + 0.007*xr + 0.007*port',\n",
       " u'0.013*stealth + 0.011*desktop + 0.011*gerald + 0.010*diamond + 0.010*miller + 0.009*richard + 0.009*norton + 0.008*font + 0.008*win + 0.008*jumper',\n",
       " u'0.031*xterm + 0.017*islamic + 0.016*uucp + 0.015*georgia + 0.012*islam + 0.011*internet + 0.008*breath + 0.008*joseph + 0.008*reply + 0.008*institut',\n",
       " u'0.021*printer + 0.018*print + 0.014*arab + 0.013*bobby + 0.012*traded + 0.011*atheism + 0.010*laser + 0.008*opposit + 0.008*pictur + 0.007*andr',\n",
       " u'0.016*hockey + 0.014*player + 0.012*team + 0.010*playoff + 0.009*game + 0.008*wing + 0.008*play + 0.008*leagu + 0.008*division + 0.007*chicago',\n",
       " u'0.010*helmet + 0.009*wheel + 0.009*dx + 0.008*cach + 0.008*v + 0.008*steer + 0.008*cycl + 0.007*music + 0.007*patch + 0.007*copy',\n",
       " u'0.006*church + 0.005*truth + 0.005*belief + 0.005*god + 0.005*faith + 0.004*evidenc + 0.004*person + 0.004*bibl + 0.004*jesu + 0.004*claim',\n",
       " u'0.010*driver + 0.006*color + 0.005*window + 0.004*screen + 0.004*gateway + 0.003*memory + 0.003*softwar + 0.003*walker + 0.003*computer + 0.003*line',\n",
       " u'0.026*gordon + 0.024*surrender + 0.024*shameful + 0.024*soon + 0.022*chastity + 0.022*njxp + 0.021*bank + 0.012*diseas + 0.011*medical + 0.011*energy',\n",
       " u'0.005*game + 0.005*season + 0.004*team + 0.004*baseball + 0.004*ground + 0.004*mile + 0.004*car + 0.003*start + 0.003*honda + 0.003*pitch']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model = models.LdaModel(tfidfs, id2word=dictionary, num_topics=20, iterations=500)\n",
    "print str(lda_model)\n",
    "lda_model.print_topics(num_topics=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文章#1 のトピックを見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.34520911271624627), (2, 0.47686740045921261)]\n",
      "weight= 0.345613891544 , topic= 0.005*israel + 0.004*jesu + 0.004*israeli + 0.004*spac + 0.004*earth + 0.003*jewish + 0.003*greek + 0.003*orbit + 0.003*stat + 0.003*world + 0.003*muslim + 0.002*attack + 0.002*christ + 0.002*heard + 0.002*religion + 0.002*human + 0.002*against + 0.002*power + 0.002*father + 0.002*moon\n",
      "weight= 0.476462621634 , topic= 0.024*monitor + 0.022*video + 0.017*card + 0.014*pric + 0.012*driver + 0.011*simm + 0.010*board + 0.010*offer + 0.010*speed + 0.009*centri + 0.009*quadra + 0.008*digital + 0.008*stereo + 0.008*mous + 0.008*speaker + 0.008*c + 0.007*bit + 0.007*channel + 0.007*color + 0.007*sal\n",
      "Lines: 11\n",
      "NNTP-Posting-Host: carson.u.washington.edu\n",
      "\n",
      "A fair number of brave souls who upgraded their SI clock oscillator have\n",
      "shared their experiences for this poll. Please send a brief message detailing\n",
      "your experiences with the procedure. Top speed attained, CPU rated speed,\n",
      "add on cards and adapters, heat sinks, hour of usage per day, floppy disk\n",
      "functionality with 800 and 1.4 m floppies are especially requested.\n",
      "\n",
      "I will be summarizing in the next two days, so please add to the network\n",
      "knowledge base if you have done the clock upgrade and haven't answered this\n",
      "poll. Thanks.\n",
      "\n",
      "Guy Kuo <guykuo@u.washington.edu>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print lda_model[tfidf_model[bows[1]]]\n",
    "for topic_id, weight in lda_model[tfidf_model[bows[1]]]:\n",
    "    print 'weight=',weight,', topic=',lda_model.print_topic(topic_id, topn=20)\n",
    "print texts[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gensim は上記のベクトル表現を用いて、文書の類似度を計算する機能もあります。最も似ている文書を5個返すように指定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = similarities.MatrixSimilarity(lda_model[tfidfs], num_features=100)\n",
    "index.num_best = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最初の文章に似ている文章を求めてみます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 --> 0.999994695187\n",
      "Lines: 11\n",
      "NNTP-Posting-Host: carson.u.washington.edu\n",
      "\n",
      "A fair number of brave souls who upgraded their SI clock oscillator have\n",
      "shared their experiences for this poll. Please send a brief message detailing\n",
      "your experiences with the procedure. Top speed attained, CPU rated speed,\n",
      "add on cards and adapters, heat sinks, hour of usage per day, floppy disk\n",
      "functionality with 800 and 1.4 m floppies are especially requested.\n",
      "\n",
      "I will be summarizing in the next two days, so please add to the network\n",
      "knowledge base if you have done the clock upgrade and haven't answered this\n",
      "poll. Thanks.\n",
      "\n",
      "Guy Kuo <guykuo@u.washington.edu>\n",
      "\n",
      "2945 --> 0.997648596764\n",
      ">\n",
      ">\tI have an Adlib sound board for sale.  It includes\n",
      ">\tthe original disks, and I'll throw in a Windows 3.1\n",
      ">\t.WAV sound file driver.  For those of you that are\n",
      ">\tusing your PC Speaker for games, this will be a much\n",
      ">\twelcomed board for your PC!\n",
      ">\n",
      ">\t$70.00 includes shipping to your home or office.\n",
      ">\n",
      ">\tEmail: bitzm@columbia.dsu.edu\n",
      "\n",
      "\tConsidering that you can get a brand new Sounds Blaster\n",
      "(original) for around $80 I think this price is way too high.  Then\n",
      "again, things are worth what someone is will to pay for them....\n",
      "\n",
      "-Jason\n",
      "\n",
      "-- \n",
      "Settle down, raise a family join the PTA, \n",
      "buy some sensible shoes, and a Chevrolet\n",
      "And party 'till you're broke and they drag you away. It's ok.\n",
      "\t\t\t\t\tAl Yankovic\n",
      "\n",
      "3775 --> 0.989799261093\n",
      "   \"Analog switches/Balanced\"\n",
      "      to <All> on 04-15-93  01:08\n",
      " MF> I am trying to build a synchronous demodulator and I've hit a snag.\n",
      " MF> In my application I want to be able to change the gain of an\n",
      " MF> op amp amplifier from 1 to -1, controlable via a digital input.\n",
      " MF> The most obvious way I've come up with is to use analog switches\n",
      " MF> to adjust the gain of the op amp. The only analog switch I have\n",
      " MF> experience with it the 4066. Unfortunately I want to switch an\n",
      " MF> AC signal which goes from about -5V to 5V, and the 4066 is only\n",
      " MF> for positive signals.\n",
      "\n",
      "    How about using a 4053 it has a seperate ground for the\n",
      "    analog outputs.  It would get you 3 bits.\n",
      "\n",
      " MF> Another part which caught my eye was the Analog Devices AD630. This\n",
      " MF> is a balanced demodulator which appears to fill exactly the need I\n",
      " MF> have. The data sheet was somewhat skimpy on application notes. Could\n",
      " MF> someone comment on using this chip for the following application?\n",
      "\n",
      "    Or how about a multiplying D/A convertor?  This is\n",
      "    essentiallty what you are makeing.\n",
      "\n",
      "\n",
      "                Stephen Cyberman@Toz.Buffalo.NY.US\n",
      "             Mangled on Fri  04-16-1993  at 13:36:11\n",
      "\n",
      "... Catch the Blue Wave!\n",
      "---\n",
      " * Blue Wave/QWK v2.12 *\n",
      "                          \n",
      "\n",
      "3494 --> 0.978718996048\n",
      "the price again! \n",
      "\n",
      "Cobra 146 GTL Single side band w/mike  --> $75 or best offer!\n",
      "\n",
      "\n",
      "dave\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------Cal Poly,  \t\tLife, Liberty, and the\n",
      "SLO, CA 93401\t\tPursuit of Land Speed Records.\n",
      "\t\t\t\t-Autobahn Commuters\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "1566 --> 0.975165605545\n",
      "wstuartj@lucky.ecn.purdue.edu (W Stuart Jones) writes:\n",
      "> I want to go from 512K to 1M VRAM on my Quadra 800.  How many 512K SIMMS \n",
      "> do I\n",
      "> need to buy?  Is the current 512K soldered on the board or do I need to take\n",
      "> out the current VRAM before I add more?\n",
      "\n",
      "You need to add two 256K VRAM SIMMs;  512K VRAM SIMMs will not work in any \n",
      "of the Quadra or Centris machines.  There is already 512K of VRAM soldered \n",
      "to the logic board.  You add the two 256K SIMMs to this to give you a \n",
      "total of 1 MB.\n",
      "\n",
      "- Dale Adams\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,sim in index[lda_model[tfidf_model[bows[1]]]]:\n",
    "    print i,'-->',sim\n",
    "    print texts[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実は、文章#1 はコンピュータ関係の文章としてきれいに識別できていますが、文章#0 はあまりきれいに識別できていません。\n",
    "（時間があれば、1 を 0 に変えて眺めてみてください。）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
